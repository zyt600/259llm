==========================================
LongBench SFT训练配置 (QLoRA)
==========================================
模型: google/gemma-3-270m-it
GPU: 3
训练方式: QLoRA 4-bit (r=16, alpha=32)
训练轮数: 3
评估间隔: 60 步 (完整测试集)
批处理大小: 4
梯度累积: 8
最大长度: 8192
输出目录: ./training_output3
训练数据集: qmsum
==========================================
评估: TruthfulQA + QMSum 完整测试集
综合分数 = accuracy + rougeL + avg_max_score
==========================================

执行命令: python3 train.py     --model_name google/gemma-3-270m-it     --gpu 3     --num_epochs 3     --eval_steps 60     --batch_size 4     --gradient_accumulation_steps 8     --max_length 8192     --output_dir ./training_output3     --train_datasets qmsum     --lora_r 16     --lora_alpha 32


======================================================================
训练配置参数
======================================================================

【模型配置】
  模型名称: google/gemma-3-270m-it
  GPU IDs: [3]
  训练方式: 纯 LoRA
  LoRA秩: 16
  LoRA alpha: 32

【训练参数】
  学习率: 5e-06
  训练轮数: 3
  批处理大小: 4
  梯度累积步数: 8
  最大序列长度: 8192
  预热比例: 0.1
  权重衰减: 0.01
  BF16: True, FP16: False

【评估配置】
  评估间隔步数: 60
  保存间隔步数: 500
  评估数据集: TruthfulQA + QMSum (完整测试集)
  综合分数: accuracy + rougeL + avg_max_score

【数据集配置】
  训练数据集: qmsum
  最大训练样本数: 全部

【输出配置】
  输出目录: ./training_output3
  日志间隔步数: 10
======================================================================

开始时间: 2025-12-11 06:57:13

============================================================
第一步：初始化训练器
============================================================

============================================================
第二步：加载模型和分词器
============================================================

正在加载模型: google/gemma-3-270m-it
  使用纯 LoRA (数据类型: torch.bfloat16)
  使用默认 Attention 实现

应用 LoRA 配置:
  r=16, alpha=32, dropout=0.05
trainable params: 3,796,992 || all params: 271,895,168 || trainable%: 1.3965
模型加载完成！
  参数量: 271.90M
  可训练参数量: 3.80M

============================================================
第三步：加载LongBench训练数据
============================================================
使用子集: ['qmsum']

============================================================
加载LongBench数据集
子集数量: 1
============================================================
正在加载原始数据集: qmsum (pszemraj/qmsum-cleaned)... [train] 共 1257 个样本

总计加载 1257 个训练样本

各子集样本数:
  qmsum: 1257

正在创建SFT训练数据集...
训练数据集创建完成，共 1257 个样本

============================================================
第四步：开始SFT训练
============================================================

======================================================================
开始SFT训练
======================================================================
训练样本数: 1257
训练轮数: 3
有效批次大小: 32
评估间隔: 每 60 步 (完整测试集)
评估GPU: [3]
综合分数 = TruthfulQA_accuracy + QMSum_rougeL + TruthfulQA_avg_max_score
======================================================================

{'loss': 4.1611, 'grad_norm': 13.871988296508789, 'learning_rate': 3.7500000000000005e-06, 'epoch': 0.25}
{'loss': 4.0327, 'grad_norm': 12.933083534240723, 'learning_rate': 4.948351554413879e-06, 'epoch': 0.51}
{'loss': 3.8129, 'grad_norm': 11.358467102050781, 'learning_rate': 4.700503477950278e-06, 'epoch': 0.76}
{'loss': 4.2312, 'grad_norm': 0.0, 'learning_rate': 4.267766952966369e-06, 'epoch': 1.0}
{'loss': 3.338, 'grad_norm': 7.857534885406494, 'learning_rate': 3.6865009243691015e-06, 'epoch': 1.25}

======================================================================
步骤 60: 开始全量评估 (TruthfulQA + QMSum 完整测试集)
======================================================================

============================================================
评估步骤 60: 转换为 GGUF 格式
============================================================

[1/4] 保存 LoRA adapter...
评估出错: 'NoneType' object has no attribute 'save_pretrained'
{'loss': 3.2715, 'grad_norm': 6.121274948120117, 'learning_rate': 3.0055439308300954e-06, 'epoch': 1.51}
{'loss': 3.1343, 'grad_norm': 6.046940326690674, 'learning_rate': 2.2821106431308546e-06, 'epoch': 1.76}
{'loss': 3.0498, 'grad_norm': 10.693025588989258, 'learning_rate': 1.5769846317182894e-06, 'epoch': 2.0}
{'loss': 2.9296, 'grad_norm': 5.846267223358154, 'learning_rate': 9.494112718293503e-07, 'epoch': 2.25}
{'loss': 3.0429, 'grad_norm': 5.243983745574951, 'learning_rate': 4.5211988927752026e-07, 'epoch': 2.51}
{'loss': 2.9242, 'grad_norm': 5.226084232330322, 'learning_rate': 1.2689339106741529e-07, 'epoch': 2.76}

======================================================================
步骤 120: 开始全量评估 (TruthfulQA + QMSum 完整测试集)
======================================================================

============================================================
评估步骤 120: 转换为 GGUF 格式
============================================================

[1/4] 保存 LoRA adapter...
评估出错: 'NoneType' object has no attribute 'save_pretrained'
{'loss': 2.9737, 'grad_norm': 7.680737495422363, 'learning_rate': 1.0576247944985018e-09, 'epoch': 3.0}
{'train_runtime': 1803.2665, 'train_samples_per_second': 2.091, 'train_steps_per_second': 0.067, 'train_loss': 3.408488464355469, 'epoch': 3.0}

======================================================================
训练完成！
======================================================================
总耗时: 0.50 小时
最终模型保存到: ./training_output3/final_model
评估历史保存到: ./training_output3/eval_history.json
最佳模型: step -1, 综合分数 -inf

======================================================================
执行最终全量评估
======================================================================

============================================================
评估步骤 -1: 转换为 GGUF 格式
============================================================

[1/4] 保存 LoRA adapter...
  Adapter 已保存到: ./training_output3/_temp_adapter_step_-1

[2/4] 加载原始模型并合并 LoRA...
  合并后模型已保存到: ./training_output3/_temp_eval_step_-1

[3/4] 转换为 GGUF 格式 (Q8_0)...
  GGUF 已保存到: ./training_output3/_temp_eval_step_-1.gguf

[4/4] 使用 GGUF 模型推理...
  使用 GPU: [3]
检测到GGUF模型，使用llama.cpp后端

正在使用llama.cpp加载模型: ./training_output3/_temp_eval_step_-1.gguf
GPU层数: 全部
从本地文件加载: ./training_output3/_temp_eval_step_-1.gguf
上下文长度: 32768
模型加载完成！


============================================================
数据集: QMSUM (完整测试集)
============================================================
任务: 摘要生成
描述: 基于查询的会议摘要数据集，评估模型在长文本理解和摘要生成方面的能力
正在加载LongBench QMSum数据集...
QMSum数据集加载完成，共 200 个样本

开始推理，共 200 个样本...
  推理进度 (llama.cpp) ━━━━━━━━━━━ 100% 200/200 0:13:20 • 0:00:00

✓ 推理完成！
  总样本数: 200
  总耗时: 800.65 秒
  平均速度: 0.25 样本/秒
