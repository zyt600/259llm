"""
SFTè®­ç»ƒå™¨æ¨¡å— - æ”¯æŒå®šæœŸè¯„ä¼°å’Œæ£€æŸ¥ç‚¹ä¿å­˜
"""
import os
import sys
import json
import time
import torch
import shutil
from datetime import datetime
from typing import Dict, List, Optional, Callable
from dataclasses import dataclass, field

from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    TrainingArguments,
    Trainer,
    TrainerCallback,
    TrainerState,
    TrainerControl,
    DataCollatorForSeq2Seq,
)

# æ·»åŠ çˆ¶ç›®å½•åˆ°pathä»¥å¯¼å…¥è¯„ä¼°æ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


def compute_combined_score(results: Dict) -> float:
    """
    è®¡ç®—ç»¼åˆåˆ†æ•°
    
    ç»¼åˆåˆ†æ•° = TruthfulQA accuracy + QMSum ROUGE-L + TruthfulQA avg_max_score
    
    Args:
        results: åŒ…å« qmsum å’Œ truthfulqa è¯„ä¼°ç»“æœçš„å­—å…¸
        
    Returns:
        float: ç»¼åˆåˆ†æ•°
    """
    score = 0.0
    
    # QMSum ROUGE-L
    if "qmsum" in results:
        rouge_l = results["qmsum"].get("rougeL", 0.0)
        score += rouge_l
    
    # TruthfulQA accuracy + avg_max_score
    if "truthfulqa" in results:
        accuracy = results["truthfulqa"].get("accuracy", 0.0)
        avg_max_score = results["truthfulqa"].get("avg_max_score", 0.0)
        score += accuracy + avg_max_score
    
    return score


@dataclass
class EvalResults:
    """è¯„ä¼°ç»“æœæ•°æ®ç±»"""
    step: int
    timestamp: str
    results: Dict
    combined_score: float = 0.0
    

class PeriodicEvalCallback(TrainerCallback):
    """
    å®šæœŸè¯„ä¼°å›è°ƒ - åœ¨æŒ‡å®šæ­¥æ•°æ‰§è¡Œå…¨é‡æµ‹è¯•
    """
    
    def __init__(
        self,
        eval_fn: Callable,
        eval_steps: int,
        output_dir: str,
        tokenizer,
    ):
        """
        åˆå§‹åŒ–è¯„ä¼°å›è°ƒ
        
        Args:
            eval_fn: è¯„ä¼°å‡½æ•°ï¼Œæ¥æ”¶ (model, tokenizer, step) å‚æ•°
            eval_steps: æ¯éš”å¤šå°‘æ­¥è¯„ä¼°ä¸€æ¬¡
            output_dir: è¾“å‡ºç›®å½•
            tokenizer: åˆ†è¯å™¨
        """
        self.eval_fn = eval_fn
        self.eval_steps = eval_steps
        self.output_dir = output_dir
        self.tokenizer = tokenizer  # ä¿å­˜tokenizerå¼•ç”¨
        self.eval_history = []
        self.best_score = -float('inf')
        self.best_step = -1
    
    def on_step_end(
        self,
        args: TrainingArguments,
        state: TrainerState,
        control: TrainerControl,
        model=None,
        tokenizer=None,
        **kwargs
    ):
        """æ¯æ­¥ç»“æŸæ—¶æ£€æŸ¥æ˜¯å¦éœ€è¦è¯„ä¼°"""
        if state.global_step > 0 and state.global_step % self.eval_steps == 0:
            print(f"\n{'='*70}")
            print(f"æ­¥éª¤ {state.global_step}: å¼€å§‹å…¨é‡è¯„ä¼° (TruthfulQA + QMSum å®Œæ•´æµ‹è¯•é›†)")
            print(f"{'='*70}")
            
            # æ‰§è¡Œè¯„ä¼°
            try:
                results, combined_score = self.eval_fn(
                    model=model,
                    tokenizer=self.tokenizer,  # ä½¿ç”¨ä¿å­˜çš„tokenizer
                    step=state.global_step,
                )
                
                # è®°å½•è¯„ä¼°ç»“æœ
                eval_result = EvalResults(
                    step=state.global_step,
                    timestamp=datetime.now().isoformat(),
                    results=results,
                    combined_score=combined_score
                )
                self.eval_history.append(eval_result)
                
                # æ¯æ¬¡è¯„ä¼°éƒ½ä¿å­˜ adapterï¼ˆæŒ‰æ­¥éª¤å‘½åï¼‰
                step_adapter_dir = os.path.join(self.output_dir, f"adapter_step_{state.global_step}")
                if model is not None:
                    model.save_pretrained(step_adapter_dir)
                    if self.tokenizer is not None:
                        self.tokenizer.save_pretrained(step_adapter_dir)
                    print(f"\nğŸ’¾ Adapter å·²ä¿å­˜åˆ°: {step_adapter_dir}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹
                if combined_score > self.best_score:
                    self.best_score = combined_score
                    self.best_step = state.global_step
                    print(f"ğŸ† æ–°çš„æœ€ä½³æ¨¡å‹ï¼ç»¼åˆåˆ†æ•°: {combined_score:.4f}")
                    
                    # åŒæ—¶ä¿å­˜ä¸€ä»½åˆ° best_adapter
                    best_adapter_dir = os.path.join(self.output_dir, "best_adapter")
                    if model is not None:
                        model.save_pretrained(best_adapter_dir)
                        if self.tokenizer is not None:
                            self.tokenizer.save_pretrained(best_adapter_dir)
                
                # ä¿å­˜è¯„ä¼°å†å²
                self._save_eval_history()
                
                print(f"\næ­¥éª¤ {state.global_step} è¯„ä¼°å®Œæˆ")
                print(f"ç»¼åˆåˆ†æ•°: {combined_score:.4f} (æœ€ä½³: {self.best_score:.4f} @ step {self.best_step})")
                
            except Exception as e:
                print(f"è¯„ä¼°å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
        
        return control
    
    def _save_eval_history(self):
        """ä¿å­˜è¯„ä¼°å†å²åˆ°æ–‡ä»¶"""
        history_file = os.path.join(self.output_dir, "eval_history.json")
        
        history_data = [
            {
                "step": er.step,
                "timestamp": er.timestamp,
                "combined_score": er.combined_score,
                "results": er.results
            }
            for er in self.eval_history
        ]
        
        # æ·»åŠ æœ€ä½³æ¨¡å‹ä¿¡æ¯
        summary = {
            "best_step": self.best_step,
            "best_score": self.best_score,
            "history": history_data
        }
        
        with open(history_file, "w", encoding="utf-8") as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"è¯„ä¼°å†å²å·²ä¿å­˜åˆ°: {history_file}")


class SFTTrainer:
    """
    SFTè®­ç»ƒå™¨ç±» - å°è£…å®Œæ•´çš„è®­ç»ƒæµç¨‹
    """
    
    def __init__(
        self,
        model_name: str,
        output_dir: str,
        gpu_ids: List[int],
        learning_rate: float = 2e-5,
        num_epochs: int = 3,
        max_steps: int = -1,
        batch_size: int = 4,
        gradient_accumulation_steps: int = 8,
        max_length: int = 4096,
        warmup_ratio: float = 0.1,
        weight_decay: float = 0.01,
        eval_steps: int = 500,
        save_steps: int = 500,
        logging_steps: int = 10,
        use_lora: bool = False,
        lora_r: int = 16,
        lora_alpha: int = 32,
        lora_dropout: float = 0.05,
        bf16: bool = True,
        fp16: bool = False,
        seed: int = 42,
        resume_from_checkpoint: Optional[str] = None,
    ):
        """
        åˆå§‹åŒ–SFTè®­ç»ƒå™¨
        """
        self.model_name = model_name
        self.output_dir = output_dir
        self.gpu_ids = gpu_ids
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        self.max_steps = max_steps
        self.batch_size = batch_size
        self.gradient_accumulation_steps = gradient_accumulation_steps
        self.max_length = max_length
        self.warmup_ratio = warmup_ratio
        self.weight_decay = weight_decay
        self.eval_steps = eval_steps
        self.save_steps = save_steps
        self.logging_steps = logging_steps
        self.use_lora = use_lora
        self.lora_r = lora_r
        self.lora_alpha = lora_alpha
        self.lora_dropout = lora_dropout
        self.bf16 = bf16
        self.fp16 = fp16
        self.seed = seed
        self.resume_from_checkpoint = resume_from_checkpoint
        
        self.model = None
        self.tokenizer = None
        self.trainer = None
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
    def load_model_and_tokenizer(self):
        """
        åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
        """
        print(f"\næ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_name}")
        
        # åŠ è½½tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.model_name,
            trust_remote_code=True,
            padding_side="right"
        )
        
        # è®¾ç½®padding token
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id
        
        # åŠ è½½æ¨¡å‹åˆ°ç¬¬ä¸€ä¸ªå¯è§GPU (device 0)
        # æ³¨æ„ï¼šç”±äº CUDA_VISIBLE_DEVICES å·²åœ¨è„šæœ¬ä¸­è®¾ç½®ï¼Œdevice 0 å°±æ˜¯æŒ‡å®šçš„ç¬¬ä¸€ä¸ª GPU
        device_map = {"": 0}
        
        # ç¡®å®šæ•°æ®ç±»å‹
        if self.bf16:
            torch_dtype = torch.bfloat16
        elif self.fp16:
            torch_dtype = torch.float16
        else:
            torch_dtype = torch.float32
        
        print(f"  ä½¿ç”¨çº¯ LoRA (æ•°æ®ç±»å‹: {torch_dtype})")
        
        # æ„å»ºæ¨¡å‹åŠ è½½å‚æ•°ï¼ˆçº¯ LoRAï¼Œä¸ä½¿ç”¨é‡åŒ–ï¼‰
        model_kwargs = {
            "torch_dtype": torch_dtype,
            "device_map": device_map,
            "trust_remote_code": True,
        }
        
        # åªæœ‰ç¡®è®¤ flash_attn å¯ç”¨æ—¶æ‰å¯ç”¨
        if self._check_flash_attention():
            model_kwargs["attn_implementation"] = "flash_attention_2"
            print("  ä½¿ç”¨ Flash Attention 2")
        else:
            print("  ä½¿ç”¨é»˜è®¤ Attention å®ç°")
        
        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_name,
            **model_kwargs
        )
        
        # å¯ç”¨gradient checkpointingä»¥èŠ‚çœæ˜¾å­˜
        self.model.gradient_checkpointing_enable()
        
        # å¦‚æœä½¿ç”¨LoRA
        if self.use_lora:
            self._apply_lora()
        
        print(f"æ¨¡å‹åŠ è½½å®Œæˆï¼")
        print(f"  å‚æ•°é‡: {self._count_parameters()}")
        if self.use_lora:
            print(f"  å¯è®­ç»ƒå‚æ•°é‡: {self._count_trainable_parameters()}")
    
    def _check_flash_attention(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ”¯æŒFlash Attention"""
        try:
            import flash_attn
            import importlib.metadata
            # ç¡®ä¿åŒ…å…ƒæ•°æ®å­˜åœ¨
            importlib.metadata.version("flash_attn")
            return True
        except (ImportError, Exception):
            return False
    
    def _apply_lora(self):
        """åº”ç”¨çº¯ LoRA"""
        try:
            from peft import LoraConfig, get_peft_model, TaskType
        except ImportError:
            raise ImportError("è¯·å®‰è£…peftåº“: pip install peft")
        
        print(f"\nåº”ç”¨ LoRA é…ç½®:")
        print(f"  r={self.lora_r}, alpha={self.lora_alpha}, dropout={self.lora_dropout}")
        
        # LoRAé…ç½®
        lora_config = LoraConfig(
            task_type=TaskType.CAUSAL_LM,
            r=self.lora_r,
            lora_alpha=self.lora_alpha,
            lora_dropout=self.lora_dropout,
            target_modules=["q_proj", "k_proj", "v_proj", "o_proj", 
                          "gate_proj", "up_proj", "down_proj"],
            bias="none",
        )
        
        self.model = get_peft_model(self.model, lora_config)
        self.model.print_trainable_parameters()
    
    def _count_parameters(self) -> str:
        """ç»Ÿè®¡æ¨¡å‹å‚æ•°é‡"""
        total = sum(p.numel() for p in self.model.parameters())
        if total >= 1e9:
            return f"{total/1e9:.2f}B"
        elif total >= 1e6:
            return f"{total/1e6:.2f}M"
        else:
            return f"{total/1e3:.2f}K"
    
    def _count_trainable_parameters(self) -> str:
        """ç»Ÿè®¡å¯è®­ç»ƒå‚æ•°é‡"""
        total = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        if total >= 1e9:
            return f"{total/1e9:.2f}B"
        elif total >= 1e6:
            return f"{total/1e6:.2f}M"
        else:
            return f"{total/1e3:.2f}K"
    
    def create_eval_function(self):
        """
        åˆ›å»ºè¯„ä¼°å‡½æ•°ï¼Œç”¨äºå›è°ƒ
        
        æµç¨‹ï¼š
        1. ä¿å­˜ LoRA adapter
        2. é‡æ–°åŠ è½½åŸå§‹æ¨¡å‹ï¼ˆfloat16ï¼‰å¹¶åˆå¹¶ LoRA
        3. ä¿å­˜åˆå¹¶åçš„æ¨¡å‹
        4. ä½¿ç”¨ SGLang ç›´æ¥æ¨ç†
        5. è®¡ç®—ç»¼åˆåˆ†æ•°
        """
        def eval_fn(model, tokenizer, step: int):
            """
            æ‰§è¡Œå…¨é‡è¯„ä¼°ï¼ˆTruthfulQA + QMSum å®Œæ•´æµ‹è¯•é›†ï¼‰
            ä½¿ç”¨ SGLang ç›´æ¥æ¨ç†ï¼ˆä¸è½¬æ¢ GGUFï¼‰
            """
            import gc
            from model_loader import ModelManager
            from datasets_loader import load_dataset_by_name, get_dataset_info
            from inference import InferenceRunner
            from evaluator import evaluate_dataset, save_results, save_predictions, print_summary
            
            # è¯„ä¼°çš„æ•°æ®é›†åˆ—è¡¨
            eval_datasets = ["qmsum", "truthfulqa"]
            
            all_results = {}
            all_samples = {}
            
            # ä¸´æ—¶ç›®å½•
            temp_adapter_dir = os.path.join(self.output_dir, f"_temp_adapter_step_{step}")
            temp_model_dir = os.path.join(self.output_dir, f"_temp_eval_step_{step}")
            os.makedirs(temp_adapter_dir, exist_ok=True)
            os.makedirs(temp_model_dir, exist_ok=True)
            
            print(f"\n{'='*60}")
            print(f"è¯„ä¼°æ­¥éª¤ {step}: ä½¿ç”¨ SGLang æ¨ç†")
            print(f"{'='*60}")
            
            # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
            model.eval()
            
            # 1. ä¿å­˜ LoRA adapter
            print(f"\n[1/3] ä¿å­˜ LoRA adapter...")
            model.save_pretrained(temp_adapter_dir)
            tokenizer.save_pretrained(temp_adapter_dir)
            print(f"  Adapter å·²ä¿å­˜åˆ°: {temp_adapter_dir}")
            
            # 2. é‡æ–°åŠ è½½åŸå§‹æ¨¡å‹ï¼ˆfloat16ï¼‰å¹¶åˆå¹¶ LoRA
            print(f"\n[2/3] åŠ è½½åŸå§‹æ¨¡å‹å¹¶åˆå¹¶ LoRA...")
            try:
                from peft import PeftModel
                
                # åŠ è½½åŸå§‹æ¨¡å‹ï¼ˆfloat16ï¼Œä¸é‡åŒ–ï¼‰
                base_model = AutoModelForCausalLM.from_pretrained(
                    self.model_name,
                    torch_dtype=torch.float16,
                    device_map={"": 0},
                    trust_remote_code=True,
                )
                
                # åŠ è½½å¹¶åˆå¹¶ LoRA
                peft_model = PeftModel.from_pretrained(base_model, temp_adapter_dir)
                merged_model = peft_model.merge_and_unload()
                
                # ä¿å­˜åˆå¹¶åçš„æ¨¡å‹
                merged_model.save_pretrained(temp_model_dir, safe_serialization=True)
                tokenizer.save_pretrained(temp_model_dir)
                print(f"  åˆå¹¶åæ¨¡å‹å·²ä¿å­˜åˆ°: {temp_model_dir}")
                
                # é‡Šæ”¾å†…å­˜
                del base_model, peft_model, merged_model
                gc.collect()
                torch.cuda.empty_cache()
                
            except Exception as e:
                print(f"  åˆå¹¶å¤±è´¥: {e}")
                raise
            
            # 3. ä½¿ç”¨ SGLang ç›´æ¥æ¨ç†åˆå¹¶åçš„æ¨¡å‹
            print(f"\n[3/3] ä½¿ç”¨ SGLang æ¨ç†...")
            print(f"  æ¨¡å‹è·¯å¾„: {temp_model_dir}")
            print(f"  ä½¿ç”¨ GPU: {self.gpu_ids}")
            
            try:
                with ModelManager(
                    model_name=temp_model_dir,  # åˆå¹¶åçš„ HuggingFace æ¨¡å‹ç›®å½•
                    gpu_ids=self.gpu_ids,
                    tp_size=len(self.gpu_ids),  # å¼ é‡å¹¶è¡Œ
                    mem_fraction=0.7
                ) as model_manager:
                    
                    # åˆ›å»ºæ¨ç†è¿è¡Œå™¨
                    runner = InferenceRunner(
                        engine=model_manager.engine,
                        temperature=0.0,
                        batch_size=8,
                        backend=model_manager.backend,  # åº”è¯¥æ˜¯ "sglang"
                        max_tokens=512,
                        model_path=temp_model_dir,
                        gpu_ids=self.gpu_ids
                    )
                    
                    # éå†æ¯ä¸ªæ•°æ®é›†è¿›è¡Œæ¨ç†
                    for dataset_name in eval_datasets:
                        print(f"\n{'='*60}")
                        print(f"æ•°æ®é›†: {dataset_name.upper()} (å®Œæ•´æµ‹è¯•é›†)")
                        print(f"{'='*60}")
                        
                        # æ‰“å°æ•°æ®é›†ä¿¡æ¯
                        dataset_info = get_dataset_info(dataset_name)
                        print(f"ä»»åŠ¡: {dataset_info.get('task', 'N/A')}")
                        print(f"æè¿°: {dataset_info.get('description', 'N/A')}")
                        
                        # åŠ è½½å®Œæ•´æ•°æ®é›†
                        samples = load_dataset_by_name(
                            dataset_name=dataset_name,
                            max_samples=None  # å®Œæ•´æµ‹è¯•é›†
                        )
                        
                        if not samples:
                            print(f"è­¦å‘Š: æ•°æ®é›† {dataset_name} ä¸ºç©ºï¼Œè·³è¿‡")
                            continue
                        
                        # è¿è¡Œæ¨ç†
                        print(f"\nå¼€å§‹æ¨ç†ï¼Œå…± {len(samples)} ä¸ªæ ·æœ¬...")
                        samples = runner.run(samples)
                        
                        # ä¿å­˜æ¨ç†ç»“æœ
                        all_samples[dataset_name] = samples
                
                # è¯„ä¼°é˜¶æ®µ
                print(f"\n{'='*60}")
                print("è¯„ä¼°é˜¶æ®µ")
                print(f"{'='*60}")
                
                for dataset_name, samples in all_samples.items():
                    print(f"\næ­£åœ¨è¯„ä¼° {dataset_name.upper()} æ•°æ®é›†...")
                    
                    # è¯„ä¼°ç»“æœ
                    results = evaluate_dataset(dataset_name, samples)
                    results["step"] = step
                    results["timestamp"] = datetime.now().isoformat()
                    results["model_name"] = f"{self.model_name}_step{step}"
                    
                    # ä¿å­˜ç»“æœ
                    step_output_dir = os.path.join(self.output_dir, f"eval_step_{step}")
                    os.makedirs(step_output_dir, exist_ok=True)
                    
                    save_results(
                        results=results,
                        output_dir=step_output_dir,
                        model_name=f"{self.model_name}_step{step}",
                        dataset_name=dataset_name,
                        temperature=0.0
                    )
                    
                    save_predictions(
                        samples=samples,
                        output_dir=step_output_dir,
                        model_name=f"{self.model_name}_step{step}",
                        dataset_name=dataset_name,
                        temperature=0.0
                    )
                    
                    all_results[dataset_name] = results
                
                # æ‰“å°è¯„ä¼°æ‘˜è¦
                print_summary(all_results)
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    if os.path.exists(temp_adapter_dir):
                        shutil.rmtree(temp_adapter_dir)
                    if os.path.exists(temp_model_dir):
                        shutil.rmtree(temp_model_dir)
                    print(f"\nå·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶")
                except:
                    pass
            
            # æ¢å¤è®­ç»ƒæ¨¡å¼
            model.train()
            
            # è®¡ç®—ç»¼åˆåˆ†æ•°
            combined_score = compute_combined_score(all_results)
            
            print(f"\n{'='*60}")
            print("ç»¼åˆè¯„åˆ†")
            print(f"{'='*60}")
            print(f"  QMSum ROUGE-L: {all_results.get('qmsum', {}).get('rougeL', 0):.4f}")
            print(f"  TruthfulQA Accuracy: {all_results.get('truthfulqa', {}).get('accuracy', 0):.4f}")
            print(f"  TruthfulQA Avg Max Score: {all_results.get('truthfulqa', {}).get('avg_max_score', 0):.4f}")
            print(f"  ç»¼åˆåˆ†æ•°: {combined_score:.4f}")
            print(f"{'='*60}")
            
            return all_results, combined_score
        
        return eval_fn
    
    def train(self, train_dataset):
        """
        æ‰§è¡Œè®­ç»ƒ
        
        Args:
            train_dataset: HuggingFace Datasetå¯¹è±¡
        """
        if self.model is None or self.tokenizer is None:
            self.load_model_and_tokenizer()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ DeepSpeed é…ç½®
        deepspeed_config = os.environ.get("DEEPSPEED_CONFIG", None)
        
        # åˆ›å»ºè®­ç»ƒå‚æ•°
        training_args = TrainingArguments(
            output_dir=self.output_dir,
            num_train_epochs=self.num_epochs,
            max_steps=self.max_steps,  # -1 è¡¨ç¤ºä¸é™åˆ¶
            per_device_train_batch_size=self.batch_size,
            gradient_accumulation_steps=self.gradient_accumulation_steps,
            learning_rate=self.learning_rate,
            warmup_ratio=self.warmup_ratio,
            weight_decay=self.weight_decay,
            logging_steps=self.logging_steps,
            save_steps=self.save_steps,
            save_total_limit=3,
            bf16=self.bf16,
            fp16=self.fp16,
            seed=self.seed,
            dataloader_num_workers=0,  # ç¦ç”¨å¤šè¿›ç¨‹ï¼Œé¿å…ä¸BLEURTå­è¿›ç¨‹å†²çª
            remove_unused_columns=False,
            report_to="none",  # ç¦ç”¨wandbç­‰
            optim="adamw_torch",
            lr_scheduler_type="cosine",
            gradient_checkpointing=True,
            max_grad_norm=1.0,  # æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
            deepspeed=deepspeed_config,  # DeepSpeed é…ç½®
        )
        
        # æ•°æ®æ•´ç†å™¨
        data_collator = DataCollatorForSeq2Seq(
            tokenizer=self.tokenizer,
            padding=True,
            return_tensors="pt",
        )
        
        # åˆ›å»ºè¯„ä¼°å›è°ƒ
        eval_callback = PeriodicEvalCallback(
            eval_fn=self.create_eval_function(),
            eval_steps=self.eval_steps,
            output_dir=self.output_dir,
            tokenizer=self.tokenizer,  # ä¼ å…¥tokenizer
        )
        
        # åˆ›å»ºTrainer
        self.trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            data_collator=data_collator,
            tokenizer=self.tokenizer,
            callbacks=[eval_callback],
        )
        
        # å¼€å§‹è®­ç»ƒ
        print(f"\n{'='*70}")
        print("å¼€å§‹SFTè®­ç»ƒ")
        print(f"{'='*70}")
        print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_dataset)}")
        print(f"è®­ç»ƒè½®æ•°: {self.num_epochs}")
        print(f"æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {self.batch_size * self.gradient_accumulation_steps * len(self.gpu_ids)}")
        print(f"è¯„ä¼°é—´éš”: æ¯ {self.eval_steps} æ­¥ (å®Œæ•´æµ‹è¯•é›†)")
        print(f"è¯„ä¼°GPU: {self.gpu_ids}")
        print(f"ç»¼åˆåˆ†æ•° = TruthfulQA_accuracy + QMSum_rougeL + TruthfulQA_avg_max_score")
        print(f"{'='*70}\n")
        
        start_time = time.time()
        
        # è®­ç»ƒ
        self.trainer.train(resume_from_checkpoint=self.resume_from_checkpoint)
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_model_path = os.path.join(self.output_dir, "final_model")
        self.trainer.save_model(final_model_path)
        self.tokenizer.save_pretrained(final_model_path)
        
        total_time = time.time() - start_time
        
        print(f"\n{'='*70}")
        print("è®­ç»ƒå®Œæˆï¼")
        print(f"{'='*70}")
        print(f"æ€»è€—æ—¶: {total_time/3600:.2f} å°æ—¶")
        print(f"æœ€ç»ˆæ¨¡å‹ä¿å­˜åˆ°: {final_model_path}")
        print(f"è¯„ä¼°å†å²ä¿å­˜åˆ°: {os.path.join(self.output_dir, 'eval_history.json')}")
        print(f"æœ€ä½³æ¨¡å‹: step {eval_callback.best_step}, ç»¼åˆåˆ†æ•° {eval_callback.best_score:.4f}")
        
        # æ‰§è¡Œæœ€ç»ˆè¯„ä¼°
        print(f"\n{'='*70}")
        print("æ‰§è¡Œæœ€ç»ˆå…¨é‡è¯„ä¼°")
        print(f"{'='*70}")
        
        final_results, final_score = self.create_eval_function()(
            model=self.model,
            tokenizer=self.tokenizer,
            step=-1,  # -1è¡¨ç¤ºæœ€ç»ˆè¯„ä¼°
        )
        
        # ä¿å­˜æœ€ç»ˆè¯„ä¼°ç»“æœ
        final_eval_data = {
            "combined_score": final_score,
            "best_step": eval_callback.best_step,
            "best_score": eval_callback.best_score,
            "results": final_results
        }
        
        final_eval_file = os.path.join(self.output_dir, "final_eval_results.json")
        with open(final_eval_file, "w", encoding="utf-8") as f:
            json.dump(final_eval_data, f, ensure_ascii=False, indent=2)
        
        print(f"\næœ€ç»ˆè¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {final_eval_file}")
        print(f"æœ€ç»ˆç»¼åˆåˆ†æ•°: {final_score:.4f}")
        
        return final_results, final_score
    
    def save_checkpoint(self, step: int):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        if self.trainer is not None:
            checkpoint_dir = os.path.join(self.output_dir, f"checkpoint-{step}")
            self.trainer.save_model(checkpoint_dir)
            self.tokenizer.save_pretrained(checkpoint_dir)
            print(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜åˆ°: {checkpoint_dir}")


if __name__ == "__main__":
    # æµ‹è¯•è®­ç»ƒå™¨åˆå§‹åŒ–
    trainer = SFTTrainer(
        model_name="Qwen/Qwen2-0.5B-Instruct",
        output_dir="./test_output",
        gpu_ids=[0],
        use_lora=True,
    )
    print("è®­ç»ƒå™¨åˆå§‹åŒ–æˆåŠŸï¼")
